{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import time\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from keras.models import load_model\n",
    "from imutils.video import VideoStream, FPS\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "\n",
    "path_model = '/media/sf_Google_Drive/Data Science/Deep Learning/Jason Brownlee - Deep Learning for Computer Vision/code/chapter_24 - YOLO/'\n",
    "sys.path.insert(0, path_model + 'keras-yolo3-master/')\n",
    "import yolo3_one_file_to_detect_them_all as yolo3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_court = '/media/sf_Google_Drive/LudisAI/03 - Court Mapping/'\n",
    "path_dataset = '/media/sf_Google_Drive/LudisAI/00 - Datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar el modelo y parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deeplearningcv/anaconda3/envs/cv/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(path_model + 'yolo_model.h5')\n",
    "\n",
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
    "labels = [\"person\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de coordenadas de la cancha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definicion de Coordenadas Court e Image\n",
    "\n",
    "src_pts = np.array([\n",
    "        [275,310],    # Drop izquierdo\n",
    "        [215,420],    # Cuadrado de saque izquierdo superior\n",
    "        [192,462],    # Cuadrado de saque izquierdo inferior\n",
    "        [154,536],    # Fondo izquierdo\n",
    "        [478,536],    # Puerta\n",
    "        [802,536],    # Fondo derecho\n",
    "        [767,463],    # Cuadrado de saque derecho inferior\n",
    "        [748,419],    # Cuadrado de saque derecho superior \n",
    "        [700,310]     # Drop derecho\n",
    "    ])\n",
    "\n",
    "# Four corners of the court + mid-court circle point in destination image \n",
    "# Start top-left corner and go anti-clock wise + mid-court circle point\n",
    "dst_pts = np.array([\n",
    "      [1,  1],      # Drop izquierdo\n",
    "      [1,  349],    # Cuadrado de saque izquierdo superior\n",
    "      [1,  464],    # Cuadrado de saque izquierdo inferior\n",
    "      [1,  654],    # Fondo izquierdo\n",
    "      [209,  654],  # Puerta\n",
    "      [412, 654],   # Fondo derecho\n",
    "      [412, 462],   # Cuadrado de saque derecho inferior\n",
    "      [412, 349],   # Cuadrado de saque derecho superior \n",
    "      [412, 1]      # Drop derecho\n",
    "    ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the boxes info from the tensor prediction result\n",
    "#\n",
    "# x1,y1 ------\n",
    "# |          |\n",
    "# |          |\n",
    "# |          |\n",
    "# --------x2,y2\n",
    "#\n",
    "\n",
    "def drawPlayers(im, pred_boxes, pred_classes, showResult=False):\n",
    "    \n",
    "    color = [255, 0, 0]\n",
    "    thickness = 3\n",
    "    radius = 3\n",
    "\n",
    "    i  = 0\n",
    "    for box in pred_boxes:\n",
    "\n",
    "        # Include only class Person\n",
    "        #if pred_classes[i] == 'Person':  \n",
    "\n",
    "        x1 = int(box.xmin)\n",
    "        y1 = int(box.ymin)\n",
    "        x2 = int(box.xmax)\n",
    "        y2 = int(box.ymax)\n",
    "\n",
    "        xc = x1 + int((x2 - x1)/2)\n",
    "        player_pos1 = (xc - 1, y2 - 25)\n",
    "        player_pos2 = (xc + 1, y2 + 1)\n",
    "\n",
    "        court = Polygon(src_pts)\n",
    "\n",
    "        # Draw only players that are within the court\n",
    "        if (box.classes[0] > obj_thresh) & (Point(player_pos1).within(court)):\n",
    "            if showResult:\n",
    "                print(\"[% 3d, % 3d]\" %(xc, y2))\n",
    "\n",
    "            cv2.circle(im, player_pos1, radius, color, thickness)\n",
    "            i = i + 1            \n",
    "\n",
    "    if showResult:\n",
    "        cv2.imshow('Court', im)\n",
    "        #cv2.imshow('Court', im_poly)\n",
    "        \n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "def homographyTransform(img_src, img_dst, showResult=False):\n",
    "\n",
    "    # Calculate Homography\n",
    "    h, status = cv2.findHomography(src_pts, dst_pts)\n",
    "    img_out = cv2.warpPerspective(img_src, h, (img_dst.shape[1], img_dst.shape[0]))\n",
    "\n",
    "    if showResult:\n",
    "        cv2.imshow('Court', img_out)\n",
    "        \n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    return img_out\n",
    "\n",
    "def getPlayersMask(im):\n",
    "    lower_range = np.array([255,0,0])                         # Set the Lower range value of blue in BGR\n",
    "    upper_range = np.array([255,155,155])                     # Set the Upper range value of blue in BGR\n",
    "    mask = cv2.inRange(im, lower_range, upper_range)     # Create a mask with range\n",
    "    result = cv2.bitwise_and(im, im, mask = mask)   # Performing bitwise and operation with mask in img variable\n",
    "    # cv2_imshow(result)                              \n",
    "\n",
    "    return cv2.inRange(result, lower_range, upper_range)  \n",
    "\n",
    "def drawPlayersOnCourt(im, coord, color, radius=10):\n",
    "    for pos in coord:\n",
    "        center_coordinates = (pos[0], pos[1])\n",
    "        cv2.circle(im, center_coordinates, radius, color, thickness=-1) \n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Court Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Court"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Court\n",
    "img_court = cv2.imread(path_court + 'squash_court.jpg')\n",
    "cv2.imshow('Court', img_court)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.polylines(img_court, [dst_pts], isClosed=True, color=[255,0,0], thickness=2)\n",
    "#cv2.imshow('Court', img_court)\n",
    "\n",
    "#k = cv2.waitKey(0)\n",
    "#if k == 27:\n",
    "#    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image\n",
    "cap = cv2.VideoCapture(path_dataset + 'video_test/squash-trim.avi')\n",
    "\n",
    "#cap.set(1, 1050)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "scale_percent = 50 # percent of original size\n",
    "width = int(frame.shape[1] * scale_percent / 100)\n",
    "height = int(frame.shape[0] * scale_percent / 100)\n",
    "dim = (width, height) \n",
    "\n",
    "#image = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Court', frame)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four corners of the 3D court \n",
    "# Start top-left corner and go anti-clock wise \n",
    "\n",
    "im_poly = image.copy()\n",
    "\n",
    "# cv2.fillPoly(img_src, [src_pts], 255)\n",
    "cv2.polylines(im_poly, [src_pts], isClosed=True, color=[0,255,255], thickness=2)\n",
    "\n",
    "cv2.imshow('Court', im_poly)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_h, image_w, _ = image.shape\n",
    "new_image = yolo3.preprocess_input(image, net_h, net_w)\n",
    "\n",
    "# run the prediction\n",
    "yolos = yolo_model.predict(new_image)\n",
    "boxes = []\n",
    "\n",
    "for i in range(len(yolos)):\n",
    "    # decode the output of the network\n",
    "    boxes += yolo3.decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n",
    "    \n",
    "# correct the sizes of the bounding boxes\n",
    "yolo3.correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "# suppress non-maximal boxes\n",
    "yolo3.do_nms(boxes, nms_thresh)  \n",
    "\n",
    "# draw bounding boxes on the image using labels\n",
    "yolo3.draw_boxes(image, boxes, labels, obj_thresh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show Boxes\n",
    "cv2.imshow('Boxes', image)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw Boxes on Image\n",
    "drawPlayers(image, boxes, labels, showResult=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Homography Transform\n",
    "img_out = homographyTransform(image, img_court, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Players Mask\n",
    "mask = getPlayersMask(img_out)    \n",
    "cv2.imshow('Court', img_out)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the contours from the players \"dots\" so we can reduce the coordinates\n",
    "# to the number of players on the court.\n",
    "cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "color = [255, 0, 0]   \n",
    "\n",
    "if cnts is not None:      \n",
    "    for cnt in cnts:\n",
    "        result = drawPlayersOnCourt(img_court, cnt[0], color)\n",
    "\n",
    "cv2.imshow('Court', result)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Court Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[======================================================================= ]  99%\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f9be93a0ce38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m## Reescalo el frame porque las coords de la cancha en el video estan en esta escala\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mscale_percent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;31m# percent of original size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import progressbar\n",
    "from time import sleep\n",
    "from collections import deque\n",
    "import imutils\n",
    "\n",
    "cap = cv2.VideoCapture(path_dataset + \"video_test/squash-trim.avi\")\n",
    "\n",
    "video_FourCC = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "video_fps    = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "video_duration = totalFrames / video_fps\n",
    "\n",
    "currentFrame = 0\n",
    "start_time = datetime.now()\n",
    "writer = None\n",
    "#deciles = [int(x) for x in np.linspace(0,1,11)*totalFrames]\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=totalFrames, \\\n",
    "      widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "\n",
    "bar.start()\n",
    "\n",
    "court_img = cv2.imread(path_court + 'squash_court.jpg')\n",
    "\n",
    "blue_color = (255,0,0)\n",
    "red_color = (0,0,255)\n",
    "\n",
    "coords = []\n",
    "\n",
    "# loop over frames from the video file stream (207)\n",
    "while True:     \n",
    "  \n",
    "    # read the next frame from the file\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## Reescalo el frame porque las coords de la cancha en el video estan en esta escala\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height) \n",
    "\n",
    "    frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    if writer is None:\n",
    "        writer = cv2.VideoWriter(path_dataset + 'video_test/squash-trim-mapping.mp4', \n",
    "                                 video_FourCC, video_fps, (court_img.shape[1], court_img.shape[0]), True)\n",
    "\n",
    "    if ret == True:\n",
    "        # print(currentFrame)\n",
    "\n",
    "####### Get player positions\n",
    "        frame_h, frame_w, _ = frame.shape\n",
    "        new_frame = yolo3.preprocess_input(frame, net_h, net_w)\n",
    "\n",
    "        # run the prediction\n",
    "        yolos = yolo_model.predict(new_frame)\n",
    "        boxes = []\n",
    "\n",
    "        for i in range(len(yolos)):\n",
    "            # decode the output of the network\n",
    "            boxes += yolo3.decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\n",
    "\n",
    "        # correct the sizes of the bounding boxes\n",
    "        yolo3.correct_yolo_boxes(boxes, frame_h, frame_w, net_h, net_w)\n",
    "\n",
    "        # suppress non-maximal boxes\n",
    "        yolo3.do_nms(boxes, nms_thresh)  \n",
    "\n",
    "        # draw bounding boxes on the image using labels\n",
    "        yolo3.draw_boxes(frame, boxes, labels, obj_thresh) \n",
    "\n",
    "####### Upload court\n",
    "        court = court_img.copy()\n",
    "\n",
    "####### Draw players on video frame\n",
    "        drawPlayers(frame, boxes, labels, False)\n",
    "\n",
    "        frame_out = homographyTransform(frame, court, False)\n",
    "        # cv2_imshow(img_out)\n",
    "\n",
    "        mask = getPlayersMask(frame_out)\n",
    "\n",
    "        # cv2_imshow(mask)\n",
    "\n",
    "        # Get the contours from the players \"dots\" so we can reduce the coordinates\n",
    "        # to the number of players on the court.\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "        if cnts is not None:      \n",
    "            for cnt in cnts:\n",
    "                result = drawPlayersOnCourt(court, cnt[0], blue_color)\n",
    "                coords.append(cnt[0])\n",
    "\n",
    "        writer.write(result)\n",
    "\n",
    "        currentFrame += 1\n",
    "        bar.update(currentFrame)\n",
    "        \n",
    "        if currentFrame == totalFrames:\n",
    "            break\n",
    "            \n",
    "\n",
    "# cv2_imshow(result)\n",
    "    \n",
    "writer.release()\n",
    "cap.release()\n",
    "bar.finish()\n",
    "\n",
    "pd.DataFrame(np.squeeze(coords), columns = ['pos_x', 'pos_y']).to_csv(path_dataset + 'coords.csv', \n",
    "                                                                      sep='|', decimal='.')\n",
    "\n",
    "duration = datetime.now()-start_time\n",
    "print(\"[INFO] process took {} seconds\".format(duration))\n",
    "\n",
    "print(\"Video created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.read_csv(path_dataset + 'coords.csv', sep='|', decimal='.')\n",
    "del ids['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = pd.DataFrame(np.squeeze(coords), columns = ['pos_x', 'pos_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, video_duration, bins=25):\n",
    "    \n",
    "    ## Distance and Speed calculation\n",
    "    pix2meter = 0.0002645833\n",
    "    df_dist = df.diff(periods=1).dropna().copy()\n",
    "    df_dist['dist'] = np.sqrt(df_dist['pos_x'] ** 2 + df_dist['pos_y'] ** 2)\n",
    "    distTraveled = int(np.sum(df_dist['dist']) * pix2meter)\n",
    "    speed = (distTraveled / video_duration) * 3600/1000\n",
    "    \n",
    "    \n",
    "    ## Heatmap plot\n",
    "    court = cv2.imread(path_court + 'squash_court.jpg')\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(df['pos_x'], df['pos_y'], bins=bins,normed=True)\n",
    "    #extent = [0, court.shape[1], court.shape[0], 0]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.set_xlim(0, court.shape[1])\n",
    "    ax.set_ylim(court.shape[0], 0)\n",
    "    \n",
    "    im1 = ax.imshow(court[:,:,[2,1,0]])\n",
    "\n",
    "    im2 = ax.imshow(heatmap.T, cmap='hot_r', alpha=0.8, interpolation='gaussian', \n",
    "              extent=[xedges.min(), xedges.max(), yedges.max(), yedges.min()])\n",
    "\n",
    "    plt.axis('off')\n",
    "    #plt.title(f'Heatmap: Player {idx}',fontsize=15)\n",
    "    plt.title(f'Heatmap: Matthew',fontsize=15)\n",
    "    plt.annotate(f'Court Coverage: {distTraveled} meters',(.19,.1),xycoords='figure fraction',fontsize=12)\n",
    "    plt.annotate(f'Speed: {speed} km/h',(.19,.08),xycoords='figure fraction',fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(ids, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contenidos",
   "title_sidebar": "Contenidos",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
